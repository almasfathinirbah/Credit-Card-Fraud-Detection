# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection with Python- Almas Fathin Irbah.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iLktyVxseuZHY4x5NU2lfSZHp3x-qgkf

# **Data Preparation (pt.1)**
"""

! pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

! kaggle datasets download -d kartik2112/fraud-detection

! mkdir fraud_dataset

! unzip fraud-detection.zip -d fraud_dataset

"""# **Data Preparation (pt.2)**"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import os
import seaborn as sns
import matplotlib.pyplot as plt

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# import libraries needed for this step
from sklearn import metrics
from sklearn.model_selection import train_test_split # train-test split
from sklearn.metrics import mean_squared_error, max_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score,roc_curve  # classification metrics
from imblearn.over_sampling import SMOTE # SMOTE
from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler # scaling methods

from sklearn.model_selection import GridSearchCV # grid search cross validation
from sklearn.model_selection import RandomizedSearchCV # randomized search cross validation

# supervised learning algorithms
from sklearn.ensemble import AdaBoostClassifier # Adaptive Boosting Classifier
from sklearn.ensemble import BaggingClassifier # Bootstrap Aggregating Classifier
from sklearn.tree import DecisionTreeClassifier # Decision Tree
from sklearn.naive_bayes import GaussianNB # Gaussain Naive Bayes
from xgboost import XGBClassifier #XG Boost Model
from sklearn.neighbors import KNeighborsClassifier # K-Nearest Neighbbors
from sklearn.linear_model import LogisticRegression #Logistic Regression
from sklearn.ensemble import RandomForestClassifier # Random Forest

import statsmodels.api as sm # estimates statistical models
from sklearn.feature_selection import RFE #Recursive Feature Elimination for feature selection
from sklearn import metrics
from sklearn.metrics import precision_recall_fscore_support as score
from statsmodels.stats.outliers_influence import variance_inflation_factor

import statsmodels.api as sm # estimates statistical models

from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.metrics import max_error

from math import sqrt

# visualization libraries
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')  # "error", "ignore", "always", "default", "module" or "once"

def dataset_overview(df):
    display(df.head())
    variables = df.shape[1]
    observations = df.shape[0]
    missings = df.isnull().sum().sum()
    missings_per = round(100 * df.isnull().sum().sum()/len(df),3)
    duplicated = df.duplicated().sum()
    duplicated_per = round(100 * df.duplicated().sum()/len(df),3)
    categ = len(df.select_dtypes(include=[np.number]).columns.values)
    numer = len(df.select_dtypes(exclude=[np.number]).columns.values)
    #names = ['Variables', 'Observations', 'Missings cells', 'Missing cells(%)','Duplicated rows','Duplicated rows(%)','Num cols','Categ cols']
    stats = list([variables, observations, missings, missings_per,duplicated,duplicated_per, categ, numer])
    over_df = pd.DataFrame({'General Overview':['Variables', 'Observations', 'Missings cells', 'Missing cells(%)','Duplicated rows','Duplicated rows(%)','Num cols','Categ cols'],
                           '': stats})
    over_df = over_df.set_index('General Overview')
    print(over_df)
        #################### categorical columns  ###############################################################
    print('\nVariable overview\n')
    print('Categorical variables')
    for x in list(df.select_dtypes(exclude=[np.number]).columns.values):
        print(x,'\n')
        print(f'unique values:         {len(df[x].unique())}')
        print(f'Missing values:        {df[x].isnull().sum()}')
        print(f'Missing values(%):     {df[x].isnull().sum()/len(df[x])}%')
        print(f'Mode:                  {df[x].mode()[0]}')
        print(f'Frequency:             {df[x].value_counts()[0]}\n')
        print(f'Data type:             {df[x].dtype}')
    
    #################### numerical columns  ###############################################################
    print('\nNumerical variables\n')
    for y in list(df.select_dtypes(include=[np.number]).columns.values):
        print(y,'\n')
        print(f'unique values:     {len(df[x].unique())}')
        print(f'Missing values:    {df[y].isnull().sum()}')
        print(f'Missing values(%): {df[y].isnull().sum()/len(df[y])}%')
        print(f'Minimum:           {df[y].min()}')
        print(f'Median:            {df[y].median()}')
        print(f'Mean:              {df[y].mean()}')
        print(f'Max:               {df[y].max()}')
        print(f'Data type:         {df[x].dtype}')

# combining train and test datasets

df = pd.concat([pd.read_csv('/content/fraud_dataset/fraudTest.csv'),pd.read_csv('/content/fraud_dataset/fraudTrain.csv')], ignore_index=True)
df.drop('Unnamed: 0',axis=1,inplace=True) # unnecessary column
df.head()

print(df.shape)
print(df.columns)

df.info()

dataset_overview(df)

"""# **Data Preparation (pt.3)**

## **Handle the Date Column**
"""

# Function to calculate the distance between two adress
def haversine_vectorize(lon1, lat1, lon2, lat2):

    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])

    newlon = lon2 - lon1
    newlat = lat2 - lat1

    haver_formula = np.sin(newlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(newlon/2.0)**2

    dist = 2 * np.arcsin(np.sqrt(haver_formula ))
    km = 6367 * dist #6367 for distance in KM for miles use 3958
    return km

# clean date of DOB and trans_date_trans_time
dates_list = ['trans_date_trans_time','dob']
for x in dates_list:
   df[x] = pd.to_datetime(df[x])

# get hours from the transaction
df['trans_hour'] =df['trans_date_trans_time'].dt.hour
# days when the transaction occured 
df['day_of_week'] =df['trans_date_trans_time'].dt.day_name()
# period when the transaction occured
df['year_month'] =df['trans_date_trans_time'].dt.to_period('M')
# the age of the client when the transaction occured
df['age'] = (np.round((df['trans_date_trans_time'] - df['dob'])/np.timedelta64(1,'Y')))

# create the column where the if the population is less than 25% to be rural, 25-50% ssemi-urban, and more than 50% urban
df['residence'] = pd.qcut(df.city_pop, q=[0, .25, .75, 1], labels=['rural', 'semi_urban', 'urban'])

# concanate the lat and longitude of client into one column and the same for the merchant location
df['lat_long'] = tuple(zip(*df[['lat','long']].values.T))
df['merch_ad'] = tuple(zip(*df[['merch_lat','merch_long']].values.T))

# get the full name 
fullname = df[['first','last']].apply(lambda x: ' '.join(x),axis=1)
df.insert(7,'fullname',fullname)

data_yes = df[df.is_fraud==1]
data_no = df[df.is_fraud==0]

# create the distance column
df['distance'] = haversine_vectorize(df['long'],df['lat'],df['merch_long'],df['merch_lat'])

# create age group

bins= [0,18,30,40,50,60,70, 110]
labels = ['under 18', '18 - 29', '30 - 39', '40 - 49', '50 - 59', '60 - 69', '70 or above']
df['AgeGroup'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)
print (df['AgeGroup'])

"""# **Exploratory Data Analysis**"""

#The distribution of TotalCharges per Contract type
plt.figure(figsize = (8, 4), dpi = 100)
sns.boxplot(data = df, x = "gender", y="amt", hue = "is_fraud")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.title('Gender vs Amount Transaction')
plt.show()

plt.figure(figsize = (8, 4), dpi = 100)
sns.countplot(data = df, x = "AgeGroup", hue = "gender")
plt.title('Age Group')
plt.show()

plt.figure(figsize = (20, 4), dpi = 100)
sns.countplot(data = df, x = "category", hue = "gender")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.title('Category')
plt.show()

plt.figure(figsize = (8, 4), dpi = 100)
sns.countplot(data = df, x = "trans_hour", hue = "gender")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.title('Transaction Hour')
plt.show()

plt.figure(figsize = (8, 4), dpi = 100)
sns.countplot(data = df, x = "day_of_week", hue = "gender")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.title('Transaction Day of Week')
plt.show()

plt.figure(figsize = (20, 4), dpi = 100)
sns.countplot(data = df, x = "year_month", hue = "gender")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.title('Transaction Year to Month')
plt.show()

plt.figure(figsize = (8, 4), dpi = 100)
sns.countplot(data = df, x = "residence", hue = "gender")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.title('Residence')
plt.show()

fig, ax = plt.subplots(1,3,figsize=(20,5))
ax[0].hist(df[df['amt']<=1000]['amt'], bins=50)
ax[1].hist(df[(df['is_fraud']==0) & (df['amt']<=1000)]['amt'], bins=50)
ax[2].hist(df[(df['is_fraud']==1) & (df['amt']<=1000)]['amt'], bins=50)

ax[0].set_title('Overall Amount Distribution')
ax[1].set_title('Non Fraud Amount Distribution')
ax[2].set_title('Fraud Amount Distribution')

ax[0].set_xlabel('Transaction Amount')
ax[0].set_ylabel('number of Transactions')

ax[1].set_xlabel('Transaction Amount')
ax[2].set_xlabel('Transaction Amount')
plt.show()

bins = np.linspace(200, 2000, 100)
plt.hist(df[(df['is_fraud']==0)]['amt'], bins,alpha=1, density=True, label='Non Fraud' )
plt.hist(df[(df['is_fraud']==1)]['amt'], bins,alpha=1, density=True, label='Fraud')

plt.title('Amount by percentage of transactions')

plt.xlabel('Transaction Amount')
plt.ylabel('Percentage of Transactions')
plt.show()

fig, ax = plt.subplots(1,3,figsize=(20,5))
sns.distplot(df['distance'], ax= ax[0])#age distributio
sns.distplot(df[(df['is_fraud']==0)].distance, ax= ax[1]) # age distribution for fraudulent transaction
sns.distplot(df[(df['is_fraud']==1)].distance, ax= ax[2]) # age distribution for non fraudulent transaction 

ax[0].set_title('Overall transaction vs distance Distribution')
ax[1].set_title('Non Fraud transaction vs distance Distribution')
ax[2].set_title('Fraud transaction vs distance Distribution')

plt.show()

fig, ax = plt.subplots(1,3,figsize=(30,7.5))
sns.distplot(df['unix_time'], ax= ax[0])#age distributio
sns.distplot(df[(df['is_fraud']==0)].unix_time, ax= ax[1]) # age distribution for fraudulent transaction
sns.distplot(df[(df['is_fraud']==1)].unix_time, ax= ax[2])
ax[0].set_title('Overall transaction vs time between another transaction Distribution')
ax[1].set_title('Non Fraud transaction vs time between another transaction Distribution')
ax[2].set_title('Fraud transaction vs time between another transaction Distribution')

plt.show()

ax = df.groupby(df['day_of_week'],sort=False)['trans_num'].nunique().reset_index().set_index('day_of_week').plot.bar(figsize=(8,4))
ax.set_ylabel('# of all the transactions')
ax.set_xlabel('days of a week')
ax.set_title('Week days vs all transaction')

for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2.,
            height + 3,
            '{:1.2f}%'.format(height/len(df)*100),
            ha="center", fontsize=15)
plt.show()

fraud = df[(df['is_fraud']==1)] # fraud df
not_fraud = df[(df['is_fraud']==0)] # non fraud dataframe

ax = fraud.groupby(fraud['day_of_week'],sort=False)['trans_num'].nunique().reset_index().set_index('day_of_week').plot.bar(figsize=(8,4))
ax.set_ylabel('# of fraudulent transactions')
ax.set_xlabel('days of a week')
ax.set_title('Week days vs fraudulent transaction')

for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2.,
            height + 3,
            '{:1.2f}%'.format(height/len(fraud)*100),
            ha="center", fontsize=15)
plt.show()

ax = fraud.groupby(fraud['residence'])['trans_num'].nunique().reset_index().set_index('residence').plot.bar(figsize=(20,10))
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2.,
            height + 3,
            '{:1.2f}%'.format(height/len(fraud)*100),
            ha="center", fontsize=15)
ax.set_title('residence vs transaction numbers')
plt.show()

#Timeplot

df_timeline01 = fraud.groupby(fraud['year_month'])[['trans_num','cc_num']].nunique().reset_index()
df_timeline01.columns = ['Year Month','Number of Fraud Transactions','Fraud Customers']
df_timeline01

x = np.arange(0,len(df_timeline01),1)

fig, ax = plt.subplots(1,1,figsize=(30,5))
ax.plot(x,df_timeline01['Number of Fraud Transactions'])
ax.set_xticks(x)
ax.set_xticklabels(df_timeline01['Year Month'])
ax.set_title('Fraud Transactions in 2019-2020')
ax.set_xlabel('Year Month')
ax.set_ylabel('Number of Fraud Transactions')

for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2.,
            height + 3,
            '{:1.2f}%'.format(height/len(fraud)*100),
            ha="center", fontsize=12)
    
plt.show()

x = np.arange(0,len(df_timeline01),1)

fig, ax = plt.subplots(1,1,figsize=(30,5))
ax.plot(x,df_timeline01['Fraud Customers'])
ax.set_xticks(x)
ax.set_xticklabels(df_timeline01['Year Month'])
ax.set_title('Customers in 2019-2020')
ax.set_xlabel('Year Month')
ax.set_ylabel('Number of Fraud Customers')
plt.show()

df_timeline02 = not_fraud.groupby(not_fraud['year_month'])[['trans_num','cc_num']].nunique().reset_index()
df_timeline02.columns = ['Year Month','Number of Non Fraud Transactions','Non Fraud Customers']
df_timeline02

print(df_timeline02['Number of Non Fraud Transactions'].mean())

x = np.arange(0,len(df_timeline02),1)

fig, ax = plt.subplots(1,1,figsize=(30,5))
ax.plot(x,df_timeline02['Number of Non Fraud Transactions'])
ax.set_xticks(x)
ax.set_xticklabels(df_timeline02['Year Month'])
ax.set_title('Non Fraud Transactions in 2019-2020')
ax.set_xlabel('Year Month')
ax.set_ylabel('Number of Non Fraud Transactions')
plt.show()

x = np.arange(0,len(df_timeline01),1)

fig, ax = plt.subplots(1,1,figsize=(30,5))
ax.plot(x,df_timeline02['Non Fraud Customers'])
ax.set_xticks(x)
ax.set_xticklabels(df_timeline02['Year Month'])
ax.set_title('Customers in 2019-2020')
ax.set_xlabel('Year Month')
ax.set_ylabel('Number of Non Fraud Customers')
plt.show()

#Gender
df_gender = df[['gender','trans_num']].groupby(['gender']).count().reset_index()
df_gender.columns = ['Gender','gender_count']

df_gender['percent'] = (df_gender['gender_count']/df_gender['gender_count'].sum())*100

df_gender

plt.bar(df_gender['Gender'], df_gender['gender_count'], color=(0.2, 0.4, 0.6, 0.6),  
        width = 0.4)

plt.show()

df_fraud_gender = df[['gender','is_fraud','trans_num']].groupby(['gender','is_fraud']).count().reset_index()
df_fraud_gender.columns = ['Gender','is_fraud','count']

df_fraud_gender = df_fraud_gender.merge(df_gender[['Gender','gender_count']],how='inner',\
                                  left_on='Gender',right_on='Gender')


df_fraud_gender['percent_grp'] = (df_fraud_gender['count']/df_fraud_gender['gender_count'])*100


df_fraud_gender

df_category = df[['category','trans_num']].groupby(['category']).count().reset_index()
df_category.columns = ['Category','category_count']

df_category['percent'] = (df_category['category_count']/df_category['category_count'].sum())*100

df_category.sort_values(by = ['percent'], ascending=False)

fig = plt.figure(figsize = (20, 6)) 


plt.bar(df_category['Category'], df_category['category_count'], color=(0.2, 0.4, 0.6, 0.6),  
        width = 0.4)

plt.show()

df_fraud_category = df[['category','is_fraud','trans_num']].groupby(['category','is_fraud']).count().reset_index()
df_fraud_category.columns = ['Category','is_fraud','count']

df_fraud_category = df_fraud_category.merge(df_category[['Category','category_count','percent']],how='inner',\
                                  left_on='Category',right_on='Category')


df_fraud_category['percent_grp'] = (df_fraud_category['count']/df_fraud_category['category_count'])*100

df_fraud_category.sort_values(by = ['category_count'], ascending=False)

df_fraud=df_fraud_category[df_fraud_category['is_fraud'] == 1].sort_values(by = ['percent_grp'])
df_fraud

fig = plt.figure(figsize = (20, 6)) 


plt.bar(df_fraud['Category'] , df_fraud['percent_grp'], color=(0.2, 0.4, 0.6, 0.6),  
        width = 0.4)
plt.title('Fraud Transaction (% Group) by Category')

plt.show()

import plotly
import plotly.graph_objects as go

df_merchant = df[['merchant','trans_num']].groupby(['merchant']).count().reset_index()
df_merchant.columns = ['Merchant','merchant_count']

df_merchant['percent'] = (df_merchant['merchant_count']/df_merchant['merchant_count'].sum())*100

df_merchant.sort_values(by = ['percent'], ascending=False)

df_fraud_merchant = df[['merchant','is_fraud','trans_num']].groupby(['merchant','is_fraud']).count().reset_index()
df_fraud_merchant.columns = ['Merchant','is_fraud','count']

df_fraud_merchant = df_fraud_merchant.merge(df_merchant[['Merchant','merchant_count','percent']],how='inner',\
                                  left_on='Merchant',right_on='Merchant')


df_fraud_merchant['percent_grp'] = (df_fraud_merchant['count']/df_fraud_merchant['merchant_count'])*100

df_job = df[['job','trans_num']].groupby(['job']).count().reset_index()
df_job.columns = ['Job','tran_count_by_job']

df_job['percent'] = (df_job['tran_count_by_job']/df_job['tran_count_by_job'].sum())*100

df_job.sort_values(by = ['percent'], ascending=False)

df_fraud_job = df[['job','is_fraud','trans_num']].groupby(['job','is_fraud']).count().reset_index()
df_fraud_job.columns = ['Job','is_fraud','count']

df_fraud_job =  df_fraud_job.merge(df_job[['Job','tran_count_by_job','percent']],how='inner',\
                                  left_on='Job',right_on='Job')


df_fraud_job['percent_grp'] = (df_fraud_job['count']/df_fraud_job['tran_count_by_job'])*100

job_plt_data = df_fraud_job.sort_values(by = ["tran_count_by_job"], ascending = False).head(20)
job_plt_data

job_plt_data['label'] = 'Not Fraud'
job_plt_data.loc[job_plt_data['is_fraud']==1,['label']]= 'Fraud'
job_plt_data

ne_grp = job_plt_data['Job'].unique()
print(ne_grp)

rm_grp = job_plt_data['label'].unique()
print(rm_grp)

fig = go.Figure(data=[
    go.Bar(name=rm_grp[0], x = ne_grp, y = job_plt_data[job_plt_data['label'] == rm_grp[0]]['percent_grp']),
    #go.Bar(name=rm_grp[1], x = ne_grp, y = job_plt_data[job_plt_data['label'] == rm_grp[1]]['percent_grp'])
])
# Change the bar mode
fig.update_layout(xaxis_title="Job Group "\
                  ,yaxis_title="Fraud Percent of Listings")
fig.show()

"""## **Map**"""

from ipywidgets import interact
fig = go.FigureWidget()
scatt = fig.add_histogram()

xs = df
@interact(state = df['state'].unique(), \
          gender = df['gender'].unique(),\
          age = (14,100,5),
          is_fraud = [0,1])

def update(state = 'NC',gender = 'M', age = 14,is_fraud=1):
    with fig.batch_update():
        scatt = df[(df['state'] == state) \
                   & (df['gender'] == gender) \
                   & (df['age'] >= age) \
                   & (df['is_fraud'] == is_fraud)]['amt']
        fig.data[0].x=scatt
fig.update_layout(xaxis_title="Number of transaction"
                  ,yaxis_title="Transaction amount")

dftemp_fraud = df[df['is_fraud'] == 1]
fig = go.Figure()
fig.add_trace(go.Scattergeo(
        locationmode = 'USA-states',
        lon = dftemp_fraud['long'],
        lat = dftemp_fraud['lat'],
        #text = df_sub['text'],
        marker = dict(
            #size = df_sub['total_cases']/scale,
            color = dftemp_fraud['is_fraud'],
            line_color='rgb(40,40,40)',
            line_width=0.5,
            sizemode = 'area'
        ),
        name = 'test'))
fig.update_layout( title_text = 'test',
                 geo = dict(
                     landcolor = 'rgb(217,217,217)',),
                  mapbox_style="open-street-map"
                 )

import plotly.express as px 

df_fraud = df[df['is_fraud'] == 1]

fig = px.scatter_mapbox(df_fraud, lat="lat", lon="long", hover_name="city",
                         zoom=3, height=500,
                         color="is_fraud",  color_discrete_sequence=px.colors.cyclical.IceFire)
fig.update_layout(mapbox_style="open-street-map")
fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
fig.show()

"""## **Correlation Heatmap**"""

#Display correlation heatmap
mask = np.triu(np.ones_like(df.corr()))
fig, ax = plt.subplots(figsize=(20,20))
sns.heatmap(df.corr(),annot=True, cmap="YlGnBu", mask=mask).set_title('Correlation heatmap')

"""# **Modelling**

## Preparation
"""

dframe = df.copy()
dframe = dframe.drop(['cc_num','first','last','trans_date_trans_time','fullname', 'merchant','trans_num','street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop','dob', 'merch_lat', 'merch_long','lat_long',
       'merch_ad','job','year_month', 'AgeGroup'],axis=1)
dframe = dframe.loc[:499999]
dframe

#dframe['is_fraud'].value_counts

#Gender
df_fraud_model = dframe[['is_fraud','unix_time']].groupby(['is_fraud']).count().reset_index()
df_fraud_model.columns = ['is_fraud','fraud_count']

df_fraud_model['percent'] = (df_fraud_model['fraud_count']/df_fraud_model['fraud_count'].sum())*100

df_fraud_model

# creating a dummy variable for one of the categorical variables and drop the first ones
dummy_var1 = pd.get_dummies(dframe[['category', 'day_of_week', 'gender', 'residence']], drop_first= False)
# adding the results to the master dataframe
dframe = pd.concat([dframe, dummy_var1], axis=1)
#dropping the repeated variables
dframe = dframe.drop(['category', 'day_of_week', 'gender', 'residence'],1)

# select columns to scale 
to_scale = [col for col in dframe.columns if dframe[col].max()>1]
scaler = RobustScaler()
scaled =scaler.fit_transform(dframe[to_scale])
scaled = pd.DataFrame(scaled, columns=to_scale)

# replace original columns with scaled columns
for col in scaled:
    dframe[col] = scaled[col]

#make a copy of this dataframe
df_model = dframe.copy()

X = df_model.drop(['is_fraud'],axis=1) 
y = df_model['is_fraud'] #target variable

#Train Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Resampling via SMOTE

sm = SMOTE()
X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())

# to demonstrate the effect of SMOTE over imbalanced datasets
fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize =(15, 5))
ax1.set_title('Before SMOTE')
pd.Series(y_train).value_counts().plot.bar(ax=ax1)

ax2.set_title('After SMOTE')  
pd.Series(y_train_new).value_counts().plot.bar(ax=ax2)

plt.show()

X_train, y_train = sm.fit_resample(X_train, y_train.ravel())

# let's see the correlation matrix
mask = np.triu(np.ones_like(df_model.corr()))
plt.figure(figsize= (30, 10))
sns.heatmap(df_model.corr(), annot=True, cmap= 'PuBuGn', mask= mask)
plt.show()

"""## **Training and Evaluation**

Adaboost
"""

adabc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=100, random_state=42)
adabc.fit(X_train,y_train)

print("Train Results")
pred_train = adabc.predict(X_train)

print(confusion_matrix(y_train,pred_train))
print('\n')
print(classification_report(y_train,pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = adabc.predict(X_test)

print(confusion_matrix(y_test,pred_test))
print('\n')
print(classification_report(y_test,pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

#Get the confusion matrix
cf_matrix = confusion_matrix(y_test,pred_test)

group_names = ["True Neg","False Pos","False Neg","True Pos"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

"""Decision Tree"""

#Building Decision Tree Model
dt_clf = DecisionTreeClassifier(criterion = 'gini', max_depth = 20, random_state=42)
dt_clf.fit(X_train, y_train)

print("Train Results")
pred_train = dt_clf.predict(X_train)

print(confusion_matrix(y_train, pred_train))
print('\n')
print(classification_report(y_train, pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = dt_clf.predict(X_test)

print(confusion_matrix(y_test, pred_test))
print('\n')
print(classification_report(y_test, pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

#Get the confusion matrix
cf_matrix = confusion_matrix(y_test,pred_test)

group_names = ["True Neg","False Pos","False Neg","True Pos"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

"""Gaussian Naive Bayes"""

#param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=100)}

#nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=3, cv=10, n_jobs=-1)
gnb = GaussianNB()

gnb.fit(X_train,y_train)

print("Train Results")
pred_train = gnb.predict(X_train)

print(confusion_matrix(y_train, pred_train))
print('\n')
print(classification_report(y_train, pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = gnb.predict(X_test)

print(confusion_matrix(y_test, pred_test))
print('\n')
print(classification_report(y_test, pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

#Get the confusion matrix
cf_matrix = confusion_matrix(y_test,pred_test)

group_names = ["True Neg","False Pos","False Neg","True Pos"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

"""Gradient Boosting Tress"""

# fit model no training data
xbt_model = XGBClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, verbose = 3, random_state=42)
xbt_model.fit(X_train, y_train)

print("Train Results")
pred_train = xbt_model.predict(X_train)

print(confusion_matrix(y_train, pred_train))
print('\n')
print(classification_report(y_train, pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = xbt_model.predict(X_test.values)

print(confusion_matrix(y_test, pred_test))
print('\n')
print(classification_report(y_test, pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

#Get the confusion matrix
cf_matrix = confusion_matrix(y_test,pred_test)

group_names = ["True Neg","False Pos","False Neg","True Pos"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

"""KNN"""

### Determining the number of neighbors using RandomizedSearchCV
#param_grid = {    'n_neighbors': range(1,5),    "weights": ["uniform", "distance"]}
#knn = RandomizedSearchCV(KNeighborsClassifier(), param_grid, verbose=3)
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train,y_train)

print("Train Results")
pred_train = knn.predict(X_train)

print(confusion_matrix(y_train, pred_train))
print('\n')
print(classification_report(y_train, pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = knn.predict(X_test)
5
print(confusion_matrix(y_test, pred_test))
print('\n')
print(classification_report(y_test, pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

#Get the confusion matrix
cf_matrix = confusion_matrix(y_test,pred_test)

group_names = ["True Neg","False Pos","False Neg","True Pos"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

"""Random Forest Clasifier"""

clf=RandomForestClassifier(n_estimators=200, random_state=42)
clf.fit(X_train, y_train)

print("Train Results")
pred_train = clf.predict(X_train)

print(confusion_matrix(y_train, pred_train))
print('\n')
print(classification_report(y_train, pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = clf.predict(X_test)

print(confusion_matrix(y_test, pred_test))
print('\n')
print(classification_report(y_test, pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

#Get the confusion matrix
cf_matrix = confusion_matrix(y_test,pred_test)

group_names = ["True Neg","False Pos","False Neg","True Pos"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

"""Logistic Regression"""

logreg = LogisticRegression(random_state=42)

#Building Logistic Regression  Model
logreg.fit(X_train, y_train)

print("Train Results")
pred_train = logreg.predict(X_train)

print(confusion_matrix(y_train, pred_train))
print('\n')
print(classification_report(y_train, pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = logreg.predict(X_test)

print(confusion_matrix(y_test, pred_test))
print('\n')
print(classification_report(y_test, pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

#Get the confusion matrix
cf_matrix = confusion_matrix(y_test,pred_test)

group_names = ["True Neg","False Pos","False Neg","True Pos"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

"""## **Classification Evaluation via AUROC**"""

# Instantiate the classfiers and make a list
classifiers = [AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=200),               
               DecisionTreeClassifier(criterion = 'gini', max_depth = 20, random_state=42),
               GaussianNB(priors=None, var_smoothing=0.01519911082952933), 
               XGBClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 3, verbose = 3, random_state=42),
               KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights='uniform'),
               LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=42, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False),
               RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='auto',max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None, oob_score=False, random_state=42, verbose=0, warm_start=False)            
              ]

# Define a result table as a DataFrame
result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])

# Train the models and record the results
for cls in classifiers:
    model = cls.fit(X_train, y_train)
    yproba = model.predict_proba(X_test.values)[::,1]
    
    fpr, tpr, _ = roc_curve(y_test,  yproba)
    auc = roc_auc_score(y_test, yproba)
    
    result_table = result_table.append({'classifiers':cls.__class__.__name__,
                                        'fpr':fpr, 
                                        'tpr':tpr, 
                                        'auc':auc}, ignore_index=True)

# Set name of the classifiers as index labels
result_table.set_index('classifiers', inplace=True)

# Plotting ROC curve 

fig = plt.figure(figsize=(8,6))

for i in result_table.index:
    plt.plot(result_table.loc[i]['fpr'], 
             result_table.loc[i]['tpr'], 
             label="{}, AUC={:.3f}".format(i, result_table.loc[i]['auc']))
    
plt.plot([0,1], [0,1], color='orange', linestyle='--')

plt.xticks(np.arange(0.0, 1.1, step=0.1))
plt.xlabel("False Positive Rate", fontsize=15)

plt.yticks(np.arange(0.0, 1.1, step=0.1))
plt.ylabel("True Positive Rate", fontsize=15)

plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)
plt.legend(prop={'size':13}, loc='lower right')

plt.show()

"""## **Hyperparameter**

### **Randomized Search CV**
"""

param_grid = { 
    'bootstrap': [False],
    'max_depth': [80],
    'max_features': ['sqrt'],
    'min_samples_leaf': [15],
    'min_samples_split': [2],
    'n_estimators': [500] 
}

best_rf = RandomizedSearchCV(estimator=clf, param_distributions = param_grid, cv = 3, verbose=2, n_jobs = -1)
best_rf.fit(X_train, y_train)

best_random = best_rf.best_estimator_
best_random

print("Train Results")
pred_train = best_random.predict(X_train)

print(confusion_matrix(y_train, pred_train))
print('\n')
print(classification_report(y_train, pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = best_random.predict(X_test)

print(confusion_matrix(y_test, pred_test))
print('\n')
print(classification_report(y_test, pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

"""### **Grid Search CV**"""

param_grid = { 
    'bootstrap': [False],
    'max_depth': [100],
    'max_features': ['sqrt'],
    'min_samples_leaf': [30],
    'min_samples_split': [2],
    'n_estimators': [500] 
}

best_rf = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, verbose=2, n_jobs = -1)
best_rf.fit(X_train, y_train)

best_grid = best_rf.best_estimator_
best_grid

print("Train Results")
pred_train = best_grid.predict(X_train)

print(confusion_matrix(y_train, pred_train))
print('\n')
print(classification_report(y_train, pred_train))
print('\n')
print("MAE test score:", mean_absolute_error(y_train, pred_train))
print("RMSE test score:", sqrt(mean_squared_error(y_train, pred_train)))

print("Test Results")
pred_test = best_grid.predict(X_test)

print(confusion_matrix(y_test, pred_test))
print('\n')
print(classification_report(y_test, pred_test))
print('\n')
print("MAE test score:", mean_absolute_error(y_test, pred_test))
print("RMSE test score:", sqrt(mean_squared_error(y_test, pred_test)))

"""## **Feature Important**"""

feature_importances = pd.DataFrame(clf.feature_importances_,index = X.columns,columns=['importance']).sort_values('importance',ascending=False)

import time
import numpy as np

start_time = time.time()
importances = clf.feature_importances_
std = np.std([
    tree.feature_importances_ for tree in clf.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: "
      f"{elapsed_time:.3f} seconds")

fig, ax = plt.subplots(figsize=(8,8))
feature_importances.plot.barh(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()

"""# **Business Impact**

## **Cost Benefit Analysis**
"""

pd.concat(
[df['amt'].describe(percentiles = [0.5,0.95,0.999])\
.reset_index().rename(columns={'index': 'Row Type', 'amt':'Overall Amt Distribution'}),
df.loc[df['is_fraud']==0,['amt']].describe(percentiles = [0.5,0.95,0.999])\
.reset_index(drop = 1).rename(columns={'amt':'Non Fraud Amt Distribution'}),
df.loc[df['is_fraud']==1,['amt']].describe(percentiles = [0.5,0.95,0.999])\
.reset_index(drop = 1).rename(columns={'amt':'Fraud Amt Distribution'})],
axis=1
)

#Monthly num_of_fraud_transactions  
df_timeline02

#Average number of fraudulent transaction per month
df_timeline02['Number of Non Fraud Transactions'].mean()

df_timeline01

#Average Number of transactions by month(Cost Benifit Analysis)
print(df_timeline01['Number of Fraud Transactions'].mean())

df_fraud=df[['is_fraud','trans_date_trans_time']].groupby('is_fraud').count().reset_index()
df_fraud.columns=['is_fraud','count']
df_fraud['percentage']=(df_fraud['count']/df_fraud['count'].sum())*100
df_fraud

df['ques'] = 1

print(f"Average number of transactions per month: {round(df.groupby(['year_month','ques'])['ques'].sum().mean(),2)}")
print(f"Average number of fraudulent transaction per month: {round(fraud.groupby(['year_month','is_fraud'])['is_fraud'].count().mean(),2)}")
print(f"Average amount per fraud transaction: {round(fraud.amt.sum()/len(fraud),2)}")